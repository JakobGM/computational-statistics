---
output:
  pdf_document: default
  html_document: default
---
```{r, include=FALSE}
set.seed(0)
knitr::set_parent("base.Rmd")

library(tidyverse)
library(broom)
library(tibble)
```

## Problem B

### B1

We start off by creating boxplot in order to explore how logarithm of the concentration is distributed across the three different individuals. The boxplot is shown in Figure $\ref{fig:boxplot}$. The plots suggest that there might be a difference between the persons, seeing as the variance is considerably lower for $p2$ than it is for the other individuals. We can also observe that the mean is considerably higher for $p3$ than it is for the other individuals. 

We proceed by fitting a linear model to the data, assosciating a coefficient $\beta_i,\ i = 1,2,3$ with each of the individuals. We want to test whether this model performs better than the null-model. The null-hypothesis, stating that $\beta_1 = \beta_2 = \beta_3$, is rejected at significance $\alpha = 0.05$, seeing as the $p$-value is less than 0.05. 

The linear model is fitted and the value of the F-statistic is calculated in the code below. 

```{r, fig.cap="\\label{fig:boxplot} Boxplot for each of the different groups"}
bilirubin <- here::here("reports", "report_3", "data", "bilirubin.txt") %>%
  read.table(header=T) %>%
  as_tibble()

bilirubin %>%
  mutate(log_meas = log(meas)) %>%
  ggplot(aes(x=pers, y=log_meas)) +
  geom_boxplot()

linear_model <- lm(log(meas)~pers, data=bilirubin)

summary(linear_model)

Fval <- linear_model %>%
  glance() %>%
  pull(statistic)
```

### B2

A function that randomly assigns the data to the three different groups, fits a linear model to the data and returns the F-statistics is implemented below.

```{r}
permTest <- function(df){
  perm_df <- tibble(meas = df %>%
                      pull(meas) %>% 
                      sample(),
                    pers = df %>% 
                      pull(pers)
  )
  lm(log(meas)~pers, data=perm_df) %>% 
    glance() %>% 
    pull(statistic)
}

permTest_df <- tibble(
  run = seq(1, 999),
  F_stat = 999 %>%
    rerun(permTest(bilirubin))
  ) %>%
  unnest()
```

### B3

The null-hypothesis for the permutation test is

$$
H_0: \text{All data are from the same distribution}.
$$
The F-statistic resulting from fitting a linear model to the data is suitable for use with the permutation test. This is because the F-statistic is able to capture some of the information about the difference between the three groups. The permutation test is performed below, and the resulting F-statistics are shown in Figure $\ref{fig:Fhist}$. The assosciated p-value can be seen in Table $\ref{tab:pval}$ and can be seen to be below 0.05. We therefore reject the null-hypothesis at significance $\alpha = 0.05$, which agress with the result obtained from the F-test conducted earlier. The permutation test leads to rejection of the null-hypothesis stating that the data come from same distribution. It's therefore not surprising to see that the F-test assosciated with linear model leads us to the conclusion that the full model is preferable to the null-model. 

The code for running the permutation test and computing the p-value is follows below. 
```{r, fig.cap="\\label{fig:Fhist} Histogram showing the F-statistic obtained from the different permutations. The red line is the 95th percentile while the blue represents the value of the F-statisic computed for the original data."}

perc_95 <- permTest_df %>%
  pull(F_stat) %>% 
  quantile(probs = c(0.95))

permTest_df %>%
  ggplot(aes(x=F_stat)) +
  geom_histogram(bins=50) +
  geom_vline(aes(xintercept=perc_95), color="red") +
  geom_vline(aes(xintercept=Fval), color="blue")

p_value <- permTest_df %>%
  pull(F_stat) %>%
  map_lgl(~.x >= Fval) %>%
  mean()

p_value %>% knitr::kable(caption="\\label{tab:pval} The p - value of the permutation test.",
                         col.names="P-value")
```




