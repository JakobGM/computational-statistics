---
output:
  pdf_document:
    fig_caption: yes
  html_document:
    fig_caption: yes
---

# Exercise 6 - Comparison to `INLA` and inclusion of covariate information

## a) Implementation in `R-INLA`

Now we implement the same model using `R-INLA`.

```{r}
library(INLA)
```

### Preparing the data

The same dataset will be used, but we need to duplicate the region covariate, since `INLA` forces us to have seperate covariate names for the unstructured and structured covariates.

```{r}
attach(Oral)
data <- tibble(
  region_structured = seq(1, problem$n),
  region_random = seq(1, problem$n),
  Y = Oral$Y,
  E = Oral$E
)
```

### Formulating the model

We start by specifying the priors for the precision parameters, $\kappa_u$ and $\kappa_v$, both of which are $\sim \text{Gamma}(1, 0.01)$.
It is important that we specify these priors in log-space instead, due to implementation details of `R-INLA`.

```{r}
kappa_v_hyper <- list(
  prec = list(prior = "loggamma", param = c(1, 0.01))
)
kappa_u_hyper <- kappa_v_hyper
```

`INLA` requires a graph for Germany's districts for the structured spatial components of our model.
It is by default included in the `INLA` distribution.

```{r}
g <- system.file("demodata/germany.graph", package="INLA")
```

We can now specify the components of our model, i.e. $\boldsymbol{\eta} = \boldsymbol{u} + \boldsymbol{v}$.
The hyperparameters are specified with the `hyper` argument.
The structural spatial component is named `besag` in `INLA`, while the unstructured white noise is named `iid`.
Lastly, we must set *no* zero sum constraint for the `besag` model and specify no intercept in order to *not* approximate the model $\boldsymbol{\eta} = \mu \boldsymbol{1} + \boldsymbol{u} + \boldsymbol{v}$ instead.

```{r}
formula <- Y ~
  -1 +
  f(region_structured, model="besag", graph = g, hyper = kappa_u_hyper, constr = FALSE) +
  f(region_random, model = "iid", hyper = kappa_v_hyper)
```

### Invoking `INLA` and retrieving the results

Finally, we can invoke the `inla` function in order to approximate our model parameters.
We must specify a poisson response distribution, and include our known component of the Poisson mean, $E$.
Calculation of the deviance information criterior (DIC) will also come to use later.

```{r}
inla_result <- inla(
  formula = formula,
  family = "poisson",
  data = data,
  E = E,
  control.compute = list(dic = TRUE)
)
```

We can instruct `INLA` to calculate *improved* estimates of the posterior marginals for the precision parameters $\kappa_u$ and $\kappa_v$.

```{r}
inla_result <- inla.hyperpar(inla_result)
```

Finally, we can retrieve the posterior marginals for $\kappa_u$, $\kappa_v$, $\boldsymbol{u}$, and $\boldsymbol{v}$.

```{r}
uv_marginals <- inla_result$marginals.random
inla_u <- uv_marginals$region_structured
inla_v <- uv_marginals$region_random

kappa_marginals <- inla_result$marginals.hyperpar
inla_kappa_u <- kappa_marginals$`Precision for region_structured`
inla_kappa_v <- kappa_marginals$`Precision for region_random`
```


### Analysis of results

We can now compare the results of our MCMC sampling algorithm to the result from `INLA` by plotting `INLA`'s posterior marginals on top of density histograms of our MCMC samples.

```{r, fig.width = 8.3, fig.height = 9, fig.fullwidth=TRUE, fig.cap = "\\label{fig:marginals}Plots comparing the posterior marginals obtained by INLA, drawn in red, to histograms of the MCMC-samples, drawn in grey. The y-axis is normalized such that both integrate to 1. First column shows u-components, second column the v-components, while the third shows kappa_u and kappa_v."}
plot_marginal <- function(param, marginal, binwidth) {
  #' Plot histogram of MCMC samples on top of posterior marginals
  #' obtained from INLA.
  param_samples <- usable_samples %>% pull(param)
  min_x <- min(param_samples)
  max_x <- max(param_samples)
  
  plot <- usable_samples %>%
    ggplot() +
    geom_histogram(
      aes_string(x = param, y = "..density.."),
      binwidth = binwidth
    ) +
    geom_line(
      data = data.frame(marginal),
      aes(x = x, y = y),
      color = "red"
    ) +
    xlim(min_x, max_x) +
    labs(title = param, x = "", y = "")
  return(plot)
}

plots <- list(
  # u-components
  plot_marginal("u_80", inla_u[[80]], 0.01),
  plot_marginal("u_360", inla_u[[360]], 0.01),
  plot_marginal("u_500", inla_u[[500]], 0.01),
  # v-components
  plot_marginal("v_80", inla_v[[80]], 0.01),
  plot_marginal("v_360", inla_v[[360]], 0.01),
  plot_marginal("v_500", inla_v[[500]], 0.01),
  # kappas
  plot_marginal("kappa_u", inla_kappa_u, 0.4),
  plot_marginal("kappa_v", inla_kappa_v, 5)
)

library(gridExtra)
layout <- rbind(
  c(1, 4, 7), c(1, 4, 7), c(2, 5, 7),
  c(2, 5, 8), c(3, 6, 8), c(3, 6, 8)
)
grid.arrange(
  grobs = plots,
  layout_matrix = layout,
  left = "density",
  bottom = "parameter value"
)
```

By inspecting figure \ref{fig:marginals}, we observe that the density histograms are consistent with the posterior marginals from `INLA`.

### Visual comparison

The spatially structured effects, $\exp(\hat{u}_i)$, can be visually compared. 

```{r, fig.cap = "\\label{fig:inla_germany}$u_i$ components plotted on top of the map of Germany. The MCMC result is portrayed on the left hand side, while INLA's result is portrayed on the right hand side."}
uv_summaries <- inla_result$summary.random
u_summary <- uv_summaries$region_structured
inla_exp_u_median <- u_summary$`0.5quant` %>% exp() %>% as_vector()
par(mfcol=c(1, 2))
germany.plot(
  exp_u_median,
  col=col,
  legend=TRUE,
  main = bquote("MCMC"),
  cex.mai = 1.5
)
germany.plot(
  inla_exp_u_median,
  col=col,
  legend=TRUE,
  main = bquote("INLA"),
  cex.mai = 1.5
)
```

There is no discernable difference between the results from `INLA` and the results from our MCMC samples in figure \ref{fig:inla_germany}.

## b) Smoking as new covariate

We will now add a new covariate to our data set, `smoking`, the smoking consumption of each German district.

```{r}
smoking = read.table("data/smoking.dat")$V1
data <- add_column(data, smoking) 
```

We will create two new models including this covariate.

### A linear model

The effect of smoking can be modelled as a linear effect, i.e.

$$
\eta_i = u_i + v_i + \beta_{\text{smoke}} \cdot x_{\text{smoke}}
$$

This can be achieved by adding `smoke` to the `formula` passed to `INLA`

```{r}
linear_smoking_formula <- Y ~
  -1 +
  f(region_structured, model = "besag", graph = g, hyper = kappa_u_hyper, constr = FALSE) +
  f(region_random, model = "iid", hyper = kappa_v_hyper) +
  smoking

linear_inla_result <- inla(
  formula = linear_smoking_formula,
  family = "poisson",
  data = data,
  E = E,
  control.compute = list(dic = TRUE)
)
```


### A random walk of second order

Alternatively, we can model the effect of smoking as a random walk of second order.
This is done by using the `rw2` model in `INLA`, were we will use the default prior parameters set by `INLA`.

By modelling the effect of smoking as a random walk of order 2 we assume that the observed covariates $\boldsymbol{x}_{smoke} = \begin{bmatrix}x_1, \ldots, x_N\end{bmatrix}$ satisfy 

$$
x_{i}^{\star} - 2x_{i+1}^{\star} + x_{i+2}^{\star} \sim \mathcal{N}(0, \tau^{-1}),
$$
where $\boldsymbol{x}^{\star}$ is $\boldsymbol{x}$ sorted in ascending order, and with duplicate values removed. The density of $\boldsymbol{x}$ is given by 

$$
\pi(\boldsymbol{x} \mid \tau) \propto \exp(-\frac{1}{2}\boldsymbol{x}^T\boldsymbol{Q}\boldsymbol{x})
$$
with $\boldsymbol{Q} = \tau\boldsymbol{S}$, where $\boldsymbol{S}$ ensures that the assumption regarding $\boldsymbol{x}^{\star}$ is satisified.

```{r}
nonlinear_smoking_formula <- Y ~
  -1 +
  f(region_structured, model="besag", graph = g, hyper = kappa_u_hyper, constr = FALSE) +
  f(region_random, model = "iid", hyper = kappa_v_hyper) +
  f(smoking, model = "rw2")

nonlinear_inla_result <- inla(
  formula = nonlinear_smoking_formula,
  family = "poisson",
  data = data,
  E = E,
  verbose = FALSE,
  control.compute = list(dic = TRUE)
)
```

### Comparison of the three models

We will now retrieve the deviance information criterion (DIC) for the three models from `INLA`.

```{r}
dics <- data.frame(
  `Original model` = inla_result$dic$dic,
  `Linear smoking` = linear_inla_result$dic$dic,
  `RW2 smoking` = nonlinear_inla_result$dic$dic
)
rownames(dics) <- c("DIC")
dics %>% kable(
  caption = "\\label{tab:DIC} Deviance information criterion (DIC) for the three fitted models."
)
```

Models with smaller values for DIC are to be preferred over models with larger DIC.
Based on the result from table \ref{tab:DIC} we conclude that smoking as a linear effect is the better model, with the `rw2` model close behind.
According to the DIC heuristic, the original model without `smoking` as a covariate is the least preferred model overall.


### Credible intervals

95% credibility intervals are obtained by finding the 2.5th and 97.5th percentiles of the estimated marginals of $x_i$. This is done below, and the result are plotted for all the different components. Note that $\boldsymbol{x}$ only contains 85 unique values, resulting cases where multiple components of $\boldsymbol{x}$ share the same marginal distribution.

[See this for example](http://www.maths.bath.ac.uk/~jjf23/brinla/intro.html)

```{r, fig.cap = "\\label{fig:credible_interval} Lines corresponding to the median, 97.5th percentile and 2.5th percentile of the different $\boldsymbol{x}$ - components plotted together with estimated linear smoking effect}
smoking_marginals <- nonlinear_inla_result$marginals.random$smoking

smoking_summary <- nonlinear_inla_result$summary.random$smoking

linear_smoking_summary <- linear_inla_result$summary.fixed

posterior_median <- tibble(
  ID = smoking_summary$ID,
  median = smoking_summary$`0.5quant`,
  lower = smoking_summary$`0.025quant`,
  upper = smoking_summary$`0.975quant`
)

posterior_median %>%
  ggplot(aes(x = ID)) +
  geom_line(
    aes(y = median, color = "Posterior median")
  ) +
  geom_line(
    aes(y = lower, color = "2.5% quantile")
  ) +
  geom_line(
    aes(y = upper, color = "97.5% quantile")
  ) +
  geom_abline(
    slope=linear_smoking_summary$`0.5quant`,
    intercept=-0.25, 
    linetype = "dashed",
    colour = "black"
  ) +
  xlab("Smoking value") +
  ylab("Effect")
```

It can be observed from figure \ref{fig:credible_interval} that the effect of the smoking variable changes rapidly for small values of $x_{smoke}$, remains almost constant for until $x_{smoke} \approx 50$ and then changes rapidly again as the value moves towards 100. The linear curve captures the increased effect from increased values, but does not enable the same degree of flexibility as the random walk model. 

Table \ref{tab:DIC} shows that there's a considerable benefit to adding the effect of smoking to the model. The DIC for two the smoking models are almost identical, and does, on it's own, not suggest that one of the models should be preferred to the other. It's worth noting that the added flexibility of the random walk model is not sufficient to make the DIC smaller and that the simpler, linear model could therefore be to prefer.
