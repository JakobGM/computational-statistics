# Exercise 2 - Implementation of the MCMC sampler

\newcommand{\kappau}{\kappa_u}
\newcommand{\kappav}{\kappa_v}
\newcommand{\uvec}{\boldsymbol{u}}
\newcommand{\Rmat}{\boldsymbol{R}}
\newcommand{\yvec}{\boldsymbol{y}}
\newcommand{\Evec}{\boldsymbol{E}}
\newcommand{\etavec}{\boldsymbol{E}}

## Importing the data set

We will now implement an MCMC sampler for the parameters discussed in exercise 1.
First, let's import the libraries which will be used in the implementation.

```{r}
# Lots of helper functions and new data types
library(tidyverse)

# For sparse matrix support
library(spam)

# Spatial data library
library(fields, warn.conflict=FALSE)

# Custom color scheme
library(colorspace)
col <- diverge_hcl(8)
```

The data of interest is contained in the \texttt{Oral} dataset.
The standardised mortality rates (SMR) $y_i / E_i$ can be visualized on top of the map of germany's districts.

```{r}
attach(Oral)
germany.plot(Oral$Y / Oral$E, col=col, legend=TRUE)
```

The neighbourhood structure matrix, $\Rmat$, is provided in the data file \texttt{tma4300_ex2_Rmatrix.Rdata}.

```{r}
load("data/tma4300_ex2_Rmatrix.Rdata")
```

We will now define a list named \texttt{problem}, which will contain our global state for our problem.
It will contain constants for our problem, such as $\yvec$, $\Evec$, $n$, $\Rmat$, $\alpha_u$, $\alpha_v$, $\beta_u$, and $\beta_v$.
These variables will remain constants through all the iterations of the MCMC algorithm.

```{r}
problem = list(
  y = Oral$Y,
  E = Oral$E,
  n = length(Oral$Y),
  R = R,
  alpha_u = 1,
  alpha_v = 1,
  beta_u = 0.01,
  beta_v = 0.01
)
```

## Implementing full conditional sampling functions

### $\kappa_u$ and $\kappa_v$

Implementing full conditional sampler for $\kappa_u$ and $\kappa_v$.

```{r}
draw_kappa_u <- function(u, problem) {
  shape <- (problem$n - 1) / 2 + problem$alpha_u
  rate <- 0.5 * t(u) %*% problem$R %*% u + problem$beta_u
  sample <- rgamma(shape = shape, rate = rate, n = 1)[[1]]
  return(sample)
}
```

```{r}
draw_kappa_v <- function(eta, u, problem) {
  shape <- problem$n / 2 + problem$alpha_v
  rate <- 0.5 * t(eta - u) %*% (eta - u) + problem$beta_v
  sample <- rgamma(shape = shape, rate = rate, n = 1)[[1]]
  return(sample)
}
```

### $\uvec$

Draw full conditional $\vec{u}$

```{r}
draw_u <- function(kappa_v, kappa_u, eta, problem) {
  Q <- diag.spam(x = kappa_v, nrow = problem$n) + kappa_u * problem$R
  b <- kappa_v * eta
  sample <- c(rmvnorm.canonical(n = 1, b = b, Q = Q))
  return(sample)
}
```

### $\etavec$

Draw full conditional $\vec{\eta}$

```{r}
source("data/dmvnorm.R")
draw_proposal_eta <- function(z, u, kappa_v, problem) {
  b <- problem$y + problem$E * exp(z) * (z - 1)
  c <- problem$E * exp(z)
  
  canonical_b <- kappa_v * u + b
  Q <- diag.spam(x = kappa_v, nrow = problem$n) + diag.spam(c)
  
  sample <- c(rmvnorm.canonical(n = 1, b = canonical_b, Q = Q))
  logprob <- dmvnorm.canonical(x = sample, b = canonical_b, Q = Q, log = TRUE)[[1]]
  return(list(sample = sample, logprob = logprob))
}
```

Acceptance probability

```{r}

eta_log_density <- function(eta, kappa_v, u, problem) {
  #' Proportional full conditional density for eta
  return(
    -0.5 * t(eta) %*% diag.spam(x = kappa_v, nrow = problem$n) %*% eta
    + t(eta) %*% (kappa_v * u)
    + t(eta) %*% problem$y
    - t(exp(eta)) %*% problem$E
  )
}

acceptance_probability <- function(proposal_eta, previous_eta, kappa_v, u, problem) {
  log_p_forward <- eta_log_density(
          eta = proposal_eta$sample,
          kappa_v = kappa_v,
          u = u,
          problem = problem
  )
  log_p_backward <- eta_log_density(
          eta = previous_eta$sample,
          kappa_v = kappa_v,
          u = u,
          problem = problem
  )
  
  log_q_forward <- proposal_eta$logprob
  log_q_backward <- previous_eta$logprob
  
  alpha <- exp(log_p_forward + log_q_backward - log_p_backward - log_q_forward)
  
  if (alpha > 1) {
    return(1)
  }
  return(alpha)
}
```

### Implementing the MCMC algorithm

Implement MCMC

```{r, cache = TRUE}
steps <- 5000

# Initial guess for parameters u and eta
u <- c(rep_len(0.0, problem$n))
eta <- draw_proposal_eta(z = u, u = u, kappa_v = 0.0001, problem = problem)

# Data structures for saving sample results
kappa_us <- vector()
kappa_vs <- vector()
etas <- matrix(data = NA, nrow = steps, ncol = problem$n)
us <- matrix(data = NA, nrow = steps, ncol = problem$n)

for (i in seq(1, steps)) {
  kappa_u <- draw_kappa_u(u = u, problem = problem)
  kappa_v <- draw_kappa_v(eta = eta$sample, u = u, problem = problem)
  u <- draw_u(kappa_v = kappa_v, kappa_u = kappa_u, eta = eta$sample, problem = problem)
  
  proposal_eta <- draw_proposal_eta(
          z = eta$sample,
          u = u,
          kappa_v = kappa_v,
          problem = problem
  )
  alpha <- acceptance_probability(
    proposal_eta = proposal_eta,
    previous_eta = eta,
    kappa_v = kappa_v,
    u = u,
    problem = problem
  )
  if (runif(1)[1] < alpha) {
    eta = proposal_eta
  }
  
  # Appending results
  kappa_us <- c(kappa_us, kappa_u)
  kappa_vs <- c(kappa_vs, kappa_v)
  us[i,] = u
  etas[i,] = eta$sample
}
```

## Convergence diagnostics

```{r}
vs <- etas - us

samples <- tibble(
  step = seq(1, steps),
  kappa_u = kappa_us,
  kappa_v = kappa_vs,
  u_1 = us[, 1],
  u_2 = us[, 2],
  v_1 = vs[, 1]
)
params <- colnames(samples)[-1]
```

### Trace plots

```{r}
samples %>% ggplot(aes(x = step)) +
  geom_line(aes(y = kappa_u)) +
  ylim(0, 100)
samples %>% ggplot(aes(x = step)) +
  geom_line(aes(y = kappa_v))
samples %>% ggplot(aes(x = step)) +
  geom_line(aes(y = u_1))
samples %>% ggplot(aes(x = step)) +
  geom_line(aes(y = u_2))
samples %>% ggplot(aes(x = step)) +
  geom_line(aes(y = v_1))
```

### Autocorrelation plots

```{r}
acf(samples$kappa_u)
acf(samples$kappa_v)
acf(samples$u_1)
acf(samples$u_2)
acf(samples$v_1)
```
 
### Convergence check with `geweke.diag()`
 
```{r}
library(coda)
library(kableExtra)

burnins <- seq(1, steps/10)
effective_samples <- samples[-burnins, -1]
z_statistics <- geweke.diag(
  effective_samples,
  frac1=0.1, frac2=0.5
)$z
p_values <- pnorm(abs(z_statistics), lower.tail = FALSE)
geweke_results <- tibble(
  parameter = names(z_statistics),
  z_statistic = z_statistics,
  p_value = p_values
)
geweke_results %>% kable()
```
