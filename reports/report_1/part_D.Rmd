---
output:
  pdf_document: default
  html_document: default
---
## Problem D: Rejection sampling and importance sampling

We now consider a specific recombination rate in genetics given by the data of Rao, C. R. [-@Roa].
197 counts are classified into four categories, $\vec{y} = (y_1, y_2, y_3, y_4)$.
These are assumed to be multinomially distributed, and the data is given in Table 1.

```{r, echo=FALSE}
library(ggplot2)
library(tibble)
library(knitr)
library(kableExtra)
library(purrr)
data <- tibble(
  cellCount = c("$y_1 = 125$", "$y_2 = 18$", "$y_3 = 20$", "$y_4 = 34$"),
  probability = c("$\\frac{1}{2} + \\frac{\\theta}{4}$", "$\\frac{1 - \\theta}{4}$", "$\\frac{1 - \\theta}{4}$", "$\\frac{\\theta}{4}$")
)
data %>%
  kable(
    col.names = c("Cell count", "Probability"),
    caption = "Table 1: Genetic linkage data"
  )
```

The multinomial mass function is given, proportionally, by

$$
f(\vec{y} | \theta) \propto (2 + \theta)^{y_1} (1-\theta)^{y_2 + y_3} \theta^{y_4}.
$$

Using Beta(1, 1) as a prior for $\theta$, i.e. a uniform prior, yields the following posterior density

$$
  f(\theta | \vec{y}) = d \cdot h(\theta | \vec{y}) \\
  h(\theta) := (2 + \theta)^{y_1} (1-\theta)^{y_2 + y_3} \theta^{y_4} \\
  d := \int_0^1 h(\theta | \vec{y}) \text{d}\theta > 0
$$

Here we have introduced the unknown normalizing constant $d$ for $h(\theta | \vec{y})$.

### 1. Rejection sampling algorithm

We will now implement the rejection sampling algorithm for $f(\theta|\vec{y})$.
The proposal density, $g(\theta | \vec{y})$, is chosen to be the uniform distribution $\mathcal{U}(0, 1)$.
Thus,

$$
g(\theta | \vec{y}) \equiv 1.
$$

The acceptance probability thus becomes

$$
\alpha = \frac{1}{c} \cdot \frac{f(\theta)}{g(\theta)} = \frac{d}{c} \cdot h(\theta | \vec{y}) \in [0, 1].
$$

Notice that neither $c$ nor $d$ are known to us, but we can numerically approximate their proportion as

$$
\frac{1}{\beta} := \frac{c}{d} = \max_{\theta} h(\theta | \vec{y})
$$

Such that the acceptance probability can be written as
$$
\alpha = \beta \cdot h(\theta | \vec{y})
$$

We now implement a function constructor, which given $\vec{y}$, returns $\hat{f}(\theta)$ such that
$\max_{\theta} \hat{f}(\theta) = 1$.

```{r}
construct_f <- function(y) {
  #' Return proportional distribution function for f which satisfies max(f) = 1

  # Proportional function of f in log-space
  unscaled_log_f <- function(theta) {
    y[1] * log(2 + theta) + (y[2] + y[3]) * log(1 - theta) + y[4] * log(theta)
  }

  # Find the maxima of this function in log-space
  log_maxima <- optimize(
    f = unscaled_log_f,
    maximum = TRUE,
    interval = c(0, 1)
  )$objective
  
  # Scale f to have max value 1
  # NB! This does not integrate to 1, so it is not a proper density function!
  # You can use make_density for that purpose.
  scaled_f <- function(theta) {
    return(exp(unscaled_log_f(theta) - log_maxima))
  }
  return(scaled_f)
}
```

Remember that this is not a proper density function, as it does not integrate to $1$.
Another function constructor can be implemented to normalize $\hat{f}$. We will use
this function later for plotting comparisons.

```{r}
make_density <- function(f, lower = 0, upper = 1) {
  #' Given f, returns a new function which integrates to 1 over the given interval
  normalizer = integrate(f, lower = lower, upper = upper)$value
  normalized_function <- function(...) {
    return(f(...) / normalizer)
  }
  return(normalized_function)
}
```

We can now implement the rejection sampling algorithm, using the constructor function.
The function will also return the total number of generated proposals, which will be
used in subtask c).

```{r}
sample_theta <- function(n, y) {
  #' Generate n theta samples from f function, given 4-vector y
  #' Returns a list with thetas key to $theta,
  #' and the number of tries keyed to $tries.
  f_density <- construct_f(y = y)
  found <- vector()
  tries <- 0
  while(length(found) < n) {
    # Number of samples that remain to be found
    remaining <- n - length(found)
    tries <- tries + remaining

    # These are proposed values that might be accepted...
    x <- runif(remaining)

    # ... with acceptance probability
    alpha <- f_density(x)

    # Append the values that get accepted
    u <- runif(remaining)
    success <- u <= alpha
    found <- c(found, x[success])
  }
  return(list(theta = found, tries = tries))
}
```

We can now plot the acceptance probability, $\alpha$, as a function of $\theta$.
We will here use $\vec{y} = (125, 18, 20, 34)$, as in the provided dataset.

```{r}
y <- c(125, 18, 20, 34)
f_scaled_density <- construct_f(y = y)
df <- enframe(rnorm(1))
ggplot(data = df) + aes(x = value) +
  stat_function(
    fun = f_scaled_density,
    xlim = c(0, 1),
    mapping = aes(col = 'Acceptance probability'),
    geom = "area",
    fill = "gray"
  ) +
  geom_hline (
    yintercept = 1,
    mapping = aes(col = 'Uniform distribution')
  ) +
  scale_y_continuous(
    name = expression(alpha)
  ) +
  scale_x_continuous(
    name = expression(theta)
  ) +
  labs(
    caption = "Acceptance probability as a function of proposed parameter theta."
  )
```

We can now observe that the rejection algorithm will sample values mostly within the interval $[0.5, 0.75]$.
Realized samples will be investigated in the following section.

### 2. Posterior mean by Monte-Carlo integration

Now we sample ten million samples, $\theta_i$, from the implemented rejection algorithm.

```{r, cache=TRUE}
M <- 10000000
theta_sampling_result <- sample_theta(n = M, y = y)
theta_samples <- enframe(theta_sampling_result$theta)
```

The posterior mean can be practically derived from the samples as

$$
E\big[\theta~|~p(\theta) \sim \mathcal{U}(0, 1)\big] \approx \frac{1}{M} \sum_{i = 1}^M \theta_i
$$
Or equivalently, in R

```{r}
thetaSampleMean <- mean(theta_samples$value)
```

In order to check the correctness of the rejection sampling algorithm, we can approximate the posterior mean
by numerically solving the integral

$$
E\big[\theta~|~p(\theta) \sim \mathcal{U}(0, 1)\big] = \int_0^1 \theta \cdot f(\theta | \vec{y})~\text{d}\theta.
$$

This is done by using the $\mathtt{integrate}$ R function

```{r}
f_density <- make_density(f_scaled_density)
thetaExpectedMean <- integrate(
  f = function(theta) theta * f_density(theta),
  lower = 0,
  upper = 1
)$value
```

All these results can now be shown in a comparison plot.

```{r}
means <- tibble(
  xint = c(thetaSampleMean, thetaExpectedMean),
  grp = c("Sample mean", "Numerical mean")
)
binWidth = 0.001
theta_samples %>%
  ggplot() +
  geom_histogram(
    mapping = aes(x = value, y = ..density..),
    binwidth = binWidth,
    boundary = 0,
    size = 0
  ) +
  geom_vline(
    data = means,
    aes(
      xintercept = xint,
      col = grp,
      linetype = c("dashed", "dotted")
    )
  ) +
  stat_function(
    fun = f_density,
    xlim = c(0, 1),
    aes(col = 'Theoretical density')
  ) +
  guides(linetype = FALSE) +
  scale_x_continuous(
    name = expression(theta),
    limits = c(0, 1)
  ) +
  labs(
    title = "Histogram of parameter samples",
    caption = "The histogram of the samples is colored in grey."
  )
```

The sample histogram, which is colored in grey, perfectly coincides with the theoretical density.
This is what we would expect with ten million samples. The same can be said of the sample mean
and numerical mean. We can therefore conclude that the rejection sampling algorithm has been 
correctly implemented.

The calculated posterior means are shown in the following table.

```{r}
means %>%
  kable(
    col.names = c("Posterior mean", "Method"),
    caption = "Table 2: Posterior mean calculation comparison"
  )
```

These values are close enough to conclude that the implementation is correct.

### 3. Required iterations for one sample

The overall acceptance rate for the rejection sampling algorithm is $c^{-1}$.
We would therefore expect, on average, to generate $c$ samples before one is
accepted. Since $\mathcal{U}(0, 1)$ is used as the proposal density, we can
numerically calculate $c$ as

$$
c = \max_{\theta \in [0, 1]} f(\theta | \vec{y})
$$

We can compare this theoretical result with the numerical one, calculated earlier

```{r}
average_theta_tries <- theta_sampling_result$tries / M
cNumeric = optimize(
  f = f_density,
  interval = c(0, 1),
  maximum = TRUE
)$objective
attempts <- tibble(
  method = c("Sampling", "Theoretical"),
  attempts = c(average_theta_tries, cNumeric)
)
attempts %>%
  kable(
    caption = "Table 3: Required proposals for each accepted sample",
    col.names = c("Method", "Required proposals")
  )
```

The acceptance rate is close to the theoretical optimal.
We have now confirmed both the validity and optimality of the implemented
algorithm within the bounds of the assigned problem.


### 4. New prior

Previously, we used the prior of theta to be $p(\theta) \sim Beta(1, 1) \equiv 1$.
Now denote the posterior distribution for this prior as

$$
f_{1, 1} (\vec{y}|\theta) \propto (2 + \theta)^{y_1}(1 - \theta)^{y_2 + y_3} \theta^{y_4}
$$

Now we want to investigate the posterior mean under a new prior for $\theta$, Beta(1, 5).
We can compare these prior distributions as follows

```{r}
alpha <- 1
beta <- 5
tibble(x = c(0, 1)) %>%
  ggplot(aes(x)) +
  stat_function(
    fun = partial(dbeta, shape1 = alpha, shape2 = beta),
    aes(col = "Beta(1, 5)")
  ) +
  stat_function(
    fun = partial(dbeta, shape1 = 1, shape2 = 1),
    aes(col = "Beta(1, 1)")
  ) +
  scale_x_continuous(
    name = expression(theta)
  ) +
  scale_y_continuous(
    name = expression(p(theta)),
    limits = c(0, NA)
  ) +
  labs(
    title = "Comparison of prior distributions"
  )
```

As you can see, this new Beta(1, 5) prior heavily favours lower values for $\theta$,
compared to the uniform prior, which does not favour any domain in particular.
We can therefore expect a lower posterior mean under the new prior.

The new posterior distribution is denoted as

$$
f_{1, 5} (\vec{y}|\theta) \propto (2 + \theta)^{y_1}(1 - \theta)^{y_2 + y_3 + \mathbf{4}} \theta^{y_4}
$$

We can now use importance sampling weights in order to "resample" our existing samples from the
old posterior distribution to the new one. $f_{1, 1}$ is therefore our proposal density, and
$f_{1, 5}$ our target density. The importance sampling weight becomes

$$
w(\theta_i) = \frac{f_{1, 5}(\theta_i)}{f_{1, 1}(\theta_i)} \propto (1 - \theta)^4
$$

In order to calculate the posterior mean under the new prior, we use the identity function
as the objective function $h(\theta_i) = \theta_i$.

Since neither $f_{1, 1}$ nor $f_{1, 5}$ are normalized, we use self-normalizing importance
sampling in order to calculate the new posterior mean

$$
E\big[\theta~|~p(\theta) \sim Beta(1, 5)\big] = \frac{\sum_{i = 1}^{M} h(\theta_i) w(\theta_i)}{\sum_{i = 1}^{M} w(\theta_i)}
$$

We implement this in R, and "resample" the $M$ previously generated samples.

```{r}
posteriorMean <- function(theta_samples, beta = 5) {
  weights <- (1 - theta_samples) ** (beta - 1)
  importanceThetaMean <- sum(theta_samples * weights) / sum(weights)
  return(importanceThetaMean)
}
importanceThetaMean <- posteriorMean(theta_samples = theta_samples$value)
```

Again, for comparison, we implement the posterior densities for the old and new prior,
and calculate the expected posterior mean by numerical integration.

$$
E\big[\theta~|~p(\theta) \sim Beta(1, 5)\big] = \int_0^1 \theta \cdot f(\theta | \vec{y})(1 - \theta)^4~\text{d}\theta.
$$

```{r}
generatePosterior <- function(y, alpha = 1, beta = 5) {
  log_unscaled = function(theta) {
    y[1] * log(2 + theta) + (y[2] + y[3] + beta - 1) * log(1 - theta) + (y[4] + alpha - 1) * log(theta)
  }
  normalizingConstant <- integrate(
    f = function(theta) exp(log_unscaled(theta)),
    lower = 0,
    upper = 1
  )$value
  scaledPosterior <- function(theta) {
    return(exp(log_unscaled(theta)) / normalizingConstant)
  }
  return(scaledPosterior)
}
newPosterior <- generatePosterior(y = y, beta = 5)
newPosteriorIntegralMean <- integrate(
  f = function(theta) theta * newPosterior(theta),
  lower = 0,
  upper = 1
)$value

oldPosterior <- generatePosterior(y = y, beta = 1)
oldPosteriorIntegralMean <- integrate(
  f = function(theta) theta * oldPosterior(theta),
  lower = 0,
  upper = 1
)$value
```

We now have two different posterior densities, which are compared in the following plot

```{r}
meanResults <- tibble(
  posteriorMeans=c(
    mean(theta_samples$value),
    importanceThetaMean,
    oldPosteriorIntegralMean,
    newPosteriorIntegralMean
  ),
  prior = c(
    "Beta(1, 1)",
    "Beta(1, 5)",
    "Beta(1, 1)", 
    "Beta(1, 5)"
  ),
  method = c(
    "Sampling",
    "Sampling",
    "Numerical", 
    "Numerical"
  ),
  grp=c(
    "Old posterior asymptotic",
    "New posterior asymptotic",
    "Old posterior numerical integration",
    "New posterior numerical integration"
  )
)

ggplot(data = data.frame(x = c(0, 1))) +
  aes(x) +
  stat_function(
    fun = oldPosterior,
    xlim = c(0, 1),
    col = "red"
  ) +
  stat_function(
    fun = newPosterior,
    xlim = c(0, 1),
    col = "blue"
  ) +
  geom_vline(
    data = meanResults,
    mapping = aes(
      xintercept = posteriorMeans,
      col = prior,
      linetype = method
    )
  ) +
  scale_x_continuous(
    name = expression(theta)
  ) +
  scale_y_continuous(
    name = expression(p(theta))
  ) +
  scale_colour_manual(
    values = c("red", "blue")
  ) +
  labs(
    title = "Posterior density comparison"
  )
```

Observe that for both posterior distributions, the sample mean perfectly coincides with the theoretical numerical mean.
The distribution under the new prior is also shifted to the left, as previously postulated.

The sampling mean converges towards the theoretical mean. The rate of convergence is visualized in the following plot.

```{r}
# Take the first 10 thousand iterations with step size = 10
row_seq <- seq(10, 10000, 10)

# Subset the first k samples of theta under the uniform prior
thetaSubsets <- lapply(row_seq, function(k) theta_samples$value[1:k])

# Calculate the posterior mean under the old and new prior
meanProgression <- tibble(
  iteration = row_seq,
  oldPosterior = sapply(thetaSubsets, mean),
  newPosterior = sapply(thetaSubsets, posteriorMean)
)

# Plot the posterior mean progressions
meanProgression %>%
  ggplot(aes(x = iteration, posteriorMean)) +
  geom_line(
    aes(y = oldPosterior),
    col = "red"
  ) +
  geom_line(
    aes(y = newPosterior),
    col = "blue"
  ) +
  geom_hline(
    data = meanResults,
    aes(
      yintercept = posteriorMeans,
      col = prior,
      linetype = method
    ),
    alpha = 0.8
  ) +
  theme(legend.position = "bottom") +
  guides(col=guide_legend(nrow=3, byrow = FALSE)) +
  ylab("Posterior mean") +
  xlab("Iteration") +
  scale_y_continuous(
    breaks = c(
      seq(0.59, 0.64, 0.01),
      round(oldPosteriorIntegralMean, digits = 3),
      round(newPosteriorIntegralMean, digits = 3)
    ),
    limits = c(NA, NA)
  ) +
  scale_colour_manual(
    values = c("red", "blue")
  ) +
  theme(
    panel.grid.minor.y = element_blank()
  ) + labs(
    title = "Posterior mean progression"
  )
```

In both cases, it seems to be enough with approximately 5 thousand samples in order to calculate a relatively accurate
posterior mean for the $\theta$ parameter.
